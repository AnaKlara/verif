#!/usr/bin/env python
import sys
import argparse
import numpy as np
import verif.input
import netCDF4
import copy
import astropy.convolution
import scipy.signal


""" Convolves the Verif array across the leadtime dimension """
def convolve(array, window):
   assert(len(array.shape) == 3)
   c = np.ones([1, window, 1])
   new_array = np.nan*np.zeros(array.shape)
   new_array[:, (window-1):, :] = scipy.signal.convolve(array, c, "valid")
   return new_array


def main():
   parser = argparse.ArgumentParser(prog="accumulate", description="Accumlates a verif file. For each leadtime, sum up values in a specified number of leadtimes leading up to this time. I.e. for a file with hourly time steps, -w 24 creates 24 hour accumulations. For leadtime 36 this is the sum of leadtimes 13-36.")
   parser.add_argument('ifile', help="Verif text or NetCDF file (input)")
   parser.add_argument('ofile', help="Verif NetCDF file (output)")
   parser.add_argument('-w', type=int, help="Accumulation window (in number of timesteps). If omitted, accumulate the whole leadtime axis.", dest="w")

   if len(sys.argv) == 1:
      parser.print_help()
      sys.exit(0)

   args = parser.parse_args()

   ifile = verif.input.get_input(args.ifile)
   locations = ifile.locations
   locationids = [loc.id for loc in locations]
   leadtimes  = ifile.leadtimes
   times    = ifile.times
   lats     = [loc.lat for loc in locations]
   lons     = [loc.lon for loc in locations]
   elevs    = [loc.elev for loc in locations]

   fcst = copy.deepcopy(ifile.fcst)
   obs = copy.deepcopy(ifile.obs)

   if args.w is None:
      fcst = np.cumsum(fcst, axis=1)
      obs = np.cumsum(obs, axis=1)

   elif args.w > 1:
      if 0:
         fcst_missing = np.cumsum(np.isnan(fcst), axis=1)
         obs_missing = np.cumsum(np.isnan(obs), axis=1)
         fcst_acc = np.nancumsum(fcst, axis=1)
         obs_acc = np.nancumsum(obs, axis=1)

         diff = fcst_acc[:, (args.w):, :] - fcst_acc[:, 0:(-args.w), :]

         # Remove timesteps where there are one or more missing values in the interval
         diff[fcst_missing[:, (args.w):, :] - fcst_missing[:, 0:(-args.w), :] > 0] = np.nan
         fcst_acc[:,(args.w):, :] = diff

         # Set missing the first timesteps that don't have a complete window
         fcst_acc[:, 0:(args.w-1), :] = np.nan

         # Remove timesteps where the leadtime is missing (the previous line does not filter out the case
         # when the first leadtime is missing)
         q = np.zeros([fcst_acc.shape[0], 1, fcst_acc.shape[1]])
         fcst_acc[:, args.w-1, :] = q

         diff = obs_acc[:, (args.w):, :] - obs_acc[:, 0:(-args.w), :]
         diff[obs_missing[:, (args.w):, :] - obs_missing[:, 0:(-args.w), :] > 0] = np.nan
         diff[np.isnan(obs[:, (args.w):, :])] = np.nan
         obs_acc[:,(args.w):, :] = diff
         obs_acc[:, 0:(args.w-1), :] = np.nan
         print obs
         print obs_acc
      else:
         fcst = convolve(fcst, args.w)
         obs = convolve(obs, args.w)

   file = netCDF4.Dataset(args.ofile, 'w', format="NETCDF4")
   file.createDimension("leadtime", len(ifile.leadtimes))
   file.createDimension("time", None)
   file.createDimension("location", len(ifile.locations))
   vTime=file.createVariable("time", "i4", ("time",))
   vOffset=file.createVariable("leadtime", "f4", ("leadtime",))
   vLocation=file.createVariable("location", "f8", ("location",))
   vLat=file.createVariable("lat", "f4", ("location",))
   vLon=file.createVariable("lon", "f4", ("location",))
   vElev=file.createVariable("altitude", "f4", ("location",))
   vfcst=file.createVariable("fcst", "f4", ("time", "leadtime", "location"))
   vobs=file.createVariable("obs", "f4", ("time", "leadtime", "location"))
   file.Variable = ifile.variable.name
   file.Units = ifile.variable.units

   vobs[:] = obs
   vfcst[:] = fcst
   vTime[:] = times
   vOffset[:] = leadtimes
   vLocation[:] = locationids
   vLat[:] = lats
   vLon[:] = lons
   vElev[:] = elevs

   file.close()

if __name__ == '__main__':
   main()
